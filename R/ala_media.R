#' Image and sounds
#'
#' In addition to text data describing individual occurrences and their attributes,
#' ALA stores image and sounds associated with a given record. These can be
#' downloaded to \code{R} by first using \code{\link{ala_occurrences}()} to
#' find records that contain media, and then passing the resulting \code{recordID}
#' field to \code{\link{ala_media}()} to download those media files (see examples).
#'
#' @param taxa \code{data.frame}: generated by a call to \code{\link{select_taxa}()}. This
#' argument also accepts a vector of unique species identifiers.
#' @param filters \code{data.frame}: generated by a call to \code{\link{select_filters}()}
#' @param locations \code{string}: generated by a call to \code{\link{select_locations}()}
#' @param columns \code{data.frame}: generated by a call to \code{\link{select_columns}()}
#' @param download_dir \code{string}: path to directory to store the downloaded media
#' in
#' @return \code{data.frame} of media information if \code{metadata=TRUE}, otherwise
#' the number of images downloaded
#' @examples
#' \dontrun{
#' # Download Regent Honeyeater multimedia
#' media_data <- ala_media(
#'     taxa = select_taxa("Regent Honeyeater"),
#'     filters = select_filters(year = 2020),
#'     download_dir = "media")
#' 
#' # Download just sounds of galahs
#' media_data <- ala_media(
#'      taxa = select_taxa("Eolophus Roseicapilla"),
#'      filters = select_filters(multimedia = "Sound"))
#' }
#' @export ala_media

# TODO: Check user has provided email and give a useful message if not

ala_media <- function(taxa, filters, locations, columns, download_dir) {
  config_verbose <- getOption("galah_config")$verbose
  assert_that(is.logical(config_verbose))
  assert_that(!missing(download_dir),
  msg = "A path to an existing directory to download images to is required")
  assert_that(file.exists(download_dir))

  if (missing(taxa)) { taxa <- NULL }
  if (missing(filters)) { filters <- NULL }
  if (missing(locations)) { locations <- NULL }
  
  if (is.null(taxa) & is.null(filters) & is.null(locations)) {
    warning("No filters have been provided. All images and sounds will be downloaded.")
  }
  
  if(missing(columns)) {
    if (config_verbose) {
      message("No columns specified, default columns will be returned.")
    }
    columns <- select_columns(group = "basic")
  }
  
  # Make sure media ids are included in results
  occ_columns <- rbind(columns,
                       select_columns("images", "sounds","videos")
                       )
  # Filter to records with image/sound/video
  occ_filters <- rbind(
    filters,
    select_filters(multimedia = c("Image", "Sound", "Video"))
    )

  occ <- ala_occurrences(taxa, occ_filters, locations, occ_columns)

  occ_long <- data.frame(data.table::rbindlist(
    lapply(seq_len(nrow(occ)), function(x) {
      # get all the image, video and sound columns into one row
      splt_media <- unlist(str_split(occ[x,][c("images", "videos", "sounds")],
                                     pattern = "\""))
      media <- splt_media[nchar(splt_media) > 1 & splt_media != "NA"]
      
      if (length(media) > 0) {
        rows <- occ[x,][rep(seq_len(nrow(occ[x,])), each = length(media)), ]
        rows$media_id <- media
      } else {
        rows <- occ[x,]
      }
      rows
    }),
    fill = TRUE
  ))

  occ_long[, c("images", "sounds", "videos")] <- NULL
  
  ids <- occ_long$media_id[!is.na(occ_long$media_id)]
  
  metadata <- media_metadata(ids = ids)

  # Select only the columns we want
  names(metadata) <- rename_columns(names(metadata), type = "media")
  metadata <- metadata[names(metadata) %in% wanted_columns("media")]
  if (config_verbose) {
    message(nrow(metadata), " files will be downloaded to ", download_dir)
  }
  # join image metadata with occurrence data
  all_data <- merge(metadata, occ_long, by = "media_id")
  
  # download images
  urls <- media_urls(all_data$media_id)
  outfiles <- media_outfiles(all_data$media_id, all_data$mimetype, download_dir)
  if (config_verbose) {
    message(nrow(all_data), " files were downloaded to ", download_dir)
  }
  download_media(urls, outfiles)

  if (config_verbose) {
    message(nrow(all_data), " files were downloaded to ", download_dir)
  }
  return(all_data)
}

media_urls <- function(ids) {
  url <- parse_url(getOption("galah_server_config")$base_url_images)
  unlist(lapply(seq_len(length(ids)), function(x) {
    url$path <- c("image", as.character(ids[x]), "original")
    # may be quicker to use `paste` here?
    build_url(url)
  }))
}

media_outfiles <- function(ids, types, download_dir) {
  unlist(lapply(seq_len(length(ids)), function(x) {
    ext <- switch(types[x],
                  "image/jpeg" = ".jpg",
                  "image/png" = ".png",
                  "audio/mpeg" = ".mpg",
                  "audio/x-wav" = ".wav",
                  "audio/mp4" = ".mp4",
                  "image/gif" = ".gif",
                  "video/3gpp" = ".3gp",
                  "video/quicktime" = ".mov",
                  "audio/vnd.wave" = ".wav",
                  ""
    )
    file.path(download_dir, paste0(ids[x], ext))
  }))
}

download_media <- function(urls, outfiles) {
  # Download images in batches of 124. The limit is due to a max on the
  # number of concurrently open connections.
  # The asynchronous method is slightly quicker than downloading all
  # images in a loop
  calls <- ceiling(length(urls) / 124)
  results <- lapply(seq_len(calls - 1), function(x) {
    start <- 1 + (x - 1) * 124
    end <- x * 124
    cc <- Async$new(
      urls = urls[start:end]
    )
    res <- cc$get(disk = outfiles[start:end])
  })
  
  # TODO: Extract this part into to a function like ala_async_get()
  # Download remaining images
  start <- 1 + (calls - 1) * 124
  end <- length(urls)
  cc <- Async$new(
    urls = c(urls[start:end]), 
    headers = list(
      "User-Agent" = user_agent_string()
    )
  )
  res <- cc$get(disk = outfiles[start:end])
}

media_metadata <- function(ids) {
  res <- ala_POST(
    url = getOption("galah_server_config")$base_url_images,
    path = "/ws/imageInfoForList",
    body = list(imageIds = ids),
    encode = "json"
    )

  # parse result and convert to data.frame
  data <- fromJSON(res)
  # suppress warnings caused by different list lengths
  # need to convert back to data.frame
  df <- suppressWarnings(data.table::rbindlist(data$results))
  return(data.frame(df))
}
